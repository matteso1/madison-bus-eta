# Madison Metro ML System Configuration

# Data Configuration
data:
  source_dir: "../backend/collected_data"
  processed_dir: "./data/processed"
  features_dir: "./data/features"
  validation_dir: "./data/validation"
  
  # Data collection requirements
  min_records_per_day: 1000
  min_vehicle_records: 50000
  min_prediction_records: 200000
  
  # Feature engineering
  lookback_hours: 24
  prediction_horizon_minutes: 30
  feature_window_hours: 2

# Model Configuration
models:
  delay_prediction:
    architecture: "transformer"  # transformer, lstm, cnn
    hidden_size: 256
    num_layers: 6
    num_heads: 8
    dropout: 0.1
    learning_rate: 0.001
    batch_size: 64
    epochs: 100
    early_stopping_patience: 10
    
  demand_forecasting:
    architecture: "lstm"
    hidden_size: 128
    num_layers: 3
    dropout: 0.2
    learning_rate: 0.0005
    batch_size: 32
    epochs: 50
    
  anomaly_detection:
    architecture: "autoencoder"
    hidden_size: 64
    num_layers: 4
    learning_rate: 0.001
    batch_size: 128
    epochs: 30

# Training Configuration
training:
  device: "cuda"  # cuda, cpu
  num_workers: 4
  pin_memory: true
  mixed_precision: true
  
  # Validation
  validation_split: 0.2
  test_split: 0.1
  
  # Optimization
  optimizer: "adamw"
  scheduler: "cosine"
  weight_decay: 0.01
  gradient_clipping: 1.0

# API Configuration
api:
  host: "0.0.0.0"
  port: 8000
  workers: 4
  max_request_size: 10485760  # 10MB
  
  # Caching
  cache_ttl: 300  # 5 minutes
  max_cache_size: 1000

# Monitoring Configuration
monitoring:
  wandb:
    project: "madison-metro-ml"
    entity: "your-username"
    
  mlflow:
    tracking_uri: "sqlite:///mlflow.db"
    experiment_name: "madison-metro"
    
  # Alerts
  alert_thresholds:
    model_drift: 0.1
    prediction_latency_ms: 1000
    error_rate: 0.05

# Deployment Configuration
deployment:
  docker:
    base_image: "pytorch/pytorch:2.1.0-cuda11.8-cudnn8-devel"
    
  kubernetes:
    replicas: 3
    resources:
      requests:
        memory: "2Gi"
        cpu: "1"
        nvidia.com/gpu: "1"
      limits:
        memory: "4Gi"
        cpu: "2"
        nvidia.com/gpu: "1"
