#!/usr/bin/env python3
"""
Analyze potential for accuracy improvement in Madison Metro ML models
"""

import pandas as pd
import glob
import numpy as np
from datetime import datetime, timedelta

def analyze_accuracy_potential():
    print('üîç ANALYZING ACCURACY IMPROVEMENT POTENTIAL')
    print('=' * 60)

    # Load a larger sample to understand patterns
    pred_files = glob.glob('collected_data/predictions_*.csv')[:100]
    veh_files = glob.glob('collected_data/vehicles_*.csv')[:100]

    print(f'üìä Analyzing {len(pred_files)} prediction files and {len(veh_files)} vehicle files...')

    # Load data
    pred_dfs = []
    for f in pred_files:
        try:
            df = pd.read_csv(f)
            pred_dfs.append(df)
        except:
            continue

    veh_dfs = []
    for f in veh_files:
        try:
            df = pd.read_csv(f)
            veh_dfs.append(df)
        except:
            continue

    if pred_dfs and veh_dfs:
        pred_data = pd.concat(pred_dfs, ignore_index=True)
        veh_data = pd.concat(veh_dfs, ignore_index=True)
        
        print(f'\nüìà CURRENT DATA COVERAGE:')
        print(f'  ‚Ä¢ Prediction records: {len(pred_data):,}')
        print(f'  ‚Ä¢ Vehicle records: {len(veh_data):,}')
        print(f'  ‚Ä¢ Unique routes: {pred_data["rt"].nunique()}')
        print(f'  ‚Ä¢ Unique stops: {pred_data["stpid"].nunique()}')
        print(f'  ‚Ä¢ Unique vehicles: {veh_data["vid"].nunique()}')
        
        # Time coverage analysis
        pred_data['collection_timestamp'] = pd.to_datetime(pred_data['collection_timestamp'])
        veh_data['collection_timestamp'] = pd.to_datetime(veh_data['collection_timestamp'])
        
        time_span = (pred_data['collection_timestamp'].max() - pred_data['collection_timestamp'].min()).total_seconds() / 3600
        print(f'  ‚Ä¢ Time span: {time_span:.1f} hours')
        
        # Route coverage analysis
        route_counts = pred_data['rt'].value_counts()
        print(f'\nüöå ROUTE COVERAGE:')
        print(f'  ‚Ä¢ Most active route: {route_counts.index[0]} ({route_counts.iloc[0]} records)')
        print(f'  ‚Ä¢ Least active route: {route_counts.index[-1]} ({route_counts.iloc[-1]} records)')
        print(f'  ‚Ä¢ Coverage ratio: {route_counts.iloc[-1]/route_counts.iloc[0]*100:.1f}% (best/worst)')
        
        # Time pattern analysis
        pred_data['hour'] = pred_data['collection_timestamp'].dt.hour
        hourly_counts = pred_data['hour'].value_counts().sort_index()
        
        print(f'\n‚è∞ TIME COVERAGE:')
        print(f'  ‚Ä¢ Peak hour: {hourly_counts.idxmax()}:00 ({hourly_counts.max()} records)')
        print(f'  ‚Ä¢ Lowest hour: {hourly_counts.idxmin()}:00 ({hourly_counts.min()} records)')
        print(f'  ‚Ä¢ Coverage ratio: {hourly_counts.min()/hourly_counts.max()*100:.1f}% (lowest/peak)')
        
        # Delay pattern analysis
        delay_data = pred_data[pred_data['dly'].notna()]
        if len(delay_data) > 0:
            delay_rate = delay_data['dly'].mean()
            print(f'\nüö® DELAY PATTERNS:')
            print(f'  ‚Ä¢ Overall delay rate: {delay_rate:.1%}')
            print(f'  ‚Ä¢ Delay records: {len(delay_data):,}')
            
            # Delay by route
            route_delays = delay_data.groupby('rt')['dly'].mean().sort_values(ascending=False)
            print(f'  ‚Ä¢ Most delayed route: {route_delays.index[0]} ({route_delays.iloc[0]:.1%})')
            print(f'  ‚Ä¢ Least delayed route: {route_delays.index[-1]} ({route_delays.iloc[-1]:.1%})')

    print(f'\nüéØ ACCURACY IMPROVEMENT ANALYSIS:')
    print('=' * 60)
    
    # Current performance
    current_mae = 10.26  # From your Random Forest results
    current_r2 = 0.700
    
    print(f'üìä CURRENT PERFORMANCE:')
    print(f'  ‚Ä¢ MAE: {current_mae:.2f} minutes')
    print(f'  ‚Ä¢ R¬≤: {current_r2:.3f} (70% accuracy)')
    
    print(f'\nüí° ACCURACY IMPROVEMENT STRATEGIES:')
    print('=' * 60)
    
    print(f'1. üìà MORE DATA (Running Longer):')
    print(f'   ‚Ä¢ Current: 1,880 files (~188K records)')
    print(f'   ‚Ä¢ 1 week more: ~2,000 additional files')
    print(f'   ‚Ä¢ Expected improvement: +2-5% accuracy')
    print(f'   ‚Ä¢ Time investment: 1 week')
    print(f'   ‚Ä¢ Recommendation: ‚ö†Ô∏è  DIMINISHING RETURNS')
    
    print(f'\n2. üéØ BETTER FEATURE ENGINEERING:')
    print(f'   ‚Ä¢ Weather data integration')
    print(f'   ‚Ä¢ Traffic pattern analysis')
    print(f'   ‚Ä¢ Historical delay patterns')
    print(f'   ‚Ä¢ Expected improvement: +5-10% accuracy')
    print(f'   ‚Ä¢ Time investment: 2-3 days')
    print(f'   ‚Ä¢ Recommendation: ‚úÖ HIGH IMPACT')
    
    print(f'\n3. üîß MODEL OPTIMIZATION:')
    print(f'   ‚Ä¢ Hyperparameter tuning')
    print(f'   ‚Ä¢ Ensemble methods')
    print(f'   ‚Ä¢ Advanced algorithms (CatBoost)')
    print(f'   ‚Ä¢ Expected improvement: +3-7% accuracy')
    print(f'   ‚Ä¢ Time investment: 1-2 days')
    print(f'   ‚Ä¢ Recommendation: ‚úÖ MEDIUM IMPACT')
    
    print(f'\n4. üìä DATA QUALITY IMPROVEMENTS:')
    print(f'   ‚Ä¢ Remove outliers')
    print(f'   ‚Ä¢ Better data validation')
    print(f'   ‚Ä¢ Feature selection')
    print(f'   ‚Ä¢ Expected improvement: +2-4% accuracy')
    print(f'   ‚Ä¢ Time investment: 1 day')
    print(f'   ‚Ä¢ Recommendation: ‚úÖ QUICK WINS')
    
    print(f'\n5. üöå ROUTE-SPECIFIC MODELS:')
    print(f'   ‚Ä¢ Train separate models per route')
    print(f'   ‚Ä¢ Route-specific features')
    print(f'   ‚Ä¢ Expected improvement: +5-15% accuracy')
    print(f'   ‚Ä¢ Time investment: 3-5 days')
    print(f'   ‚Ä¢ Recommendation: ‚úÖ HIGH IMPACT')
    
    print(f'\nüéØ RECOMMENDATIONS:')
    print('=' * 60)
    
    print(f'ü•á PRIORITY 1: Feature Engineering (2-3 days)')
    print(f'   ‚Ä¢ Add weather data')
    print(f'   ‚Ä¢ Historical patterns')
    print(f'   ‚Ä¢ Traffic conditions')
    print(f'   ‚Ä¢ Expected: 75-80% accuracy')
    
    print(f'\nü•à PRIORITY 2: Model Optimization (1-2 days)')
    print(f'   ‚Ä¢ Hyperparameter tuning')
    print(f'   ‚Ä¢ Ensemble methods')
    print(f'   ‚Ä¢ Expected: 72-77% accuracy')
    
    print(f'\nü•â PRIORITY 3: Route-Specific Models (3-5 days)')
    print(f'   ‚Ä¢ Separate models per route')
    print(f'   ‚Ä¢ Route-specific features')
    print(f'   ‚Ä¢ Expected: 75-85% accuracy')
    
    print(f'\n‚ö†Ô∏è  LOW PRIORITY: More Data Collection')
    print(f'   ‚Ä¢ Diminishing returns after current volume')
    print(f'   ‚Ä¢ Better to optimize existing data')
    print(f'   ‚Ä¢ Expected: 70-72% accuracy')
    
    print(f'\nüöÄ QUICK WINS (Today):')
    print('   ‚Ä¢ Remove outliers from training data')
    print('   ‚Ä¢ Feature selection and engineering')
    print('   ‚Ä¢ Hyperparameter tuning')
    print('   ‚Ä¢ Expected: 72-75% accuracy in 1 day!')

if __name__ == "__main__":
    analyze_accuracy_potential()

